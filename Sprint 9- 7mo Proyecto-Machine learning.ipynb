{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Clasificación para la Selección Óptima de Planes Móviles en Megaline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este proyecto es ayudar a Megaline a optimizar la recomendación de sus nuevos planes móviles, Smart o Ultra. Actualmente, muchos clientes siguen utilizando planes heredados, y queremos asegurarnos de que obtengan el plan que mejor se ajuste a su uso real.\n",
    "\n",
    "Para lograr esto, vamos a desarrollar un modelo de clasificación que analizará el comportamiento de los suscriptores y recomendará uno de los nuevos planes de manera precisa. Ya hemos procesado los datos y estamos listos para crear el modelo, priorizando una exactitud mínima del 75%. Utilizaremos el conjunto de datos disponible para verificar y garantizar que el modelo cumple con los estándares de calidad esperados.\n",
    "\n",
    "Este enfoque ayudará a Megaline a ofrecer a sus clientes planes más adecuados, optimizando tanto la satisfacción del cliente como el uso de los recursos de la empresa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:#20B2AA'> Preparación y Segmentación de Datos para el Modelo de Clasificación </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intentar cargar el archivo CSV\n",
    "file_path = 'users_behavior.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Mostrar las primeras filas del dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:#800080'> Explicación: </span> Se importó y cargó el conjunto de datos, y se realizó un examen de las primeras filas para obtener una vista preliminar de la estructura y contenido del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: (2249, 5)\n",
      "Tamaño del conjunto de validación: (482, 5)\n",
      "Tamaño del conjunto de prueba: (483, 5)\n"
     ]
    }
   ],
   "source": [
    "# Dividir el dataset en conjunto de entrenamiento (70%) y conjunto de validación/prueba (30%)\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Dividir el conjunto de validación/prueba en conjunto de validación (15%) y conjunto de prueba (15%)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Mostrar el tamaño de los conjuntos\n",
    "print(f'Tamaño del conjunto de entrenamiento: {train_data.shape}')\n",
    "print(f'Tamaño del conjunto de validación: {val_data.shape}')\n",
    "print(f'Tamaño del conjunto de prueba: {test_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:#800080'> Explicación: </span> Dividir los datos: Usaremos train_test_split dos veces: una vez para dividir entre el conjunto de entrenamiento y el conjunto de validación/prueba, y luego para dividir el conjunto de validación/prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:#20B2AA'> Investigar la calidad de diferentes modelos cambiando los hiperparámetros </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo para Logistic Regression: {'C': 0.1}\n",
      "Mejor modelo para Random Forest: {'max_depth': 10, 'n_estimators': 200}\n",
      "Mejor modelo para KNN: {'n_neighbors': 7}\n",
      "Accuracy en conjunto de validación para Logistic Regression: 0.7634854771784232\n",
      "Accuracy en conjunto de validación para Random Forest: 0.8236514522821576\n",
      "Accuracy en conjunto de validación para KNN: 0.7987551867219918\n"
     ]
    }
   ],
   "source": [
    "# Definir los modelos a probar\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Hiperparámetros a probar para cada modelo\n",
    "param_grids = {\n",
    "    'Logistic Regression': {'C': [0.1, 1, 10]},\n",
    "    'Random Forest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]},\n",
    "    'KNN': {'n_neighbors': [3, 5, 7]}\n",
    "}\n",
    "\n",
    "# Resultados almacenados\n",
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    grid_search = GridSearchCV(model, param_grids[model_name], cv=5, scoring='accuracy')\n",
    "    grid_search.fit(train_data.drop('is_ultra', axis=1), train_data['is_ultra'])  # Usamos 'is_ultra' como columna objetivo\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "    print(f\"Mejor modelo para {model_name}: {grid_search.best_params_}\")\n",
    "\n",
    "# Evaluar los mejores modelos\n",
    "for model_name, model in best_models.items():\n",
    "    val_predictions = model.predict(val_data.drop('is_ultra', axis=1))\n",
    "    accuracy = accuracy_score(val_data['is_ultra'], val_predictions)\n",
    "    print(f\"Accuracy en conjunto de validación para {model_name}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:#800080'> Explicación: </span> GridSearchCV: Esta función busca automáticamente la mejor combinación de hiperparámetros, realizando una validación cruzada en cada combinación.\n",
    "Entrenamiento de diferentes modelos: Probamos Logistic Regression, Random Forest y KNN, variando los hiperparámetros como C para la regresión logística, el número de estimadores para el bosque aleatorio y el número de vecinos en KNN.\n",
    "Mejor modelo: Se obtiene el mejor modelo para cada técnica y se reporta su rendimiento en el conjunto de validación.\n",
    "Métrica de calidad: Utilizamos la precisión como métrica de rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:#20B2AA'> Comprobar la calidad del modelo usando el conjunto de prueba </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del mejor modelo en el conjunto de prueba: 0.782608695652174\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos el mejor modelo, por ejemplo el Random Forest\n",
    "best_model = best_models['Random Forest']  # Cambia este modelo si otro ha sido mejor\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "test_predictions = best_model.predict(test_data.drop('is_ultra', axis=1))\n",
    "\n",
    "# Evaluar la calidad en el conjunto de prueba\n",
    "test_accuracy = accuracy_score(test_data['is_ultra'], test_predictions)\n",
    "\n",
    "print(f\"Precisión del mejor modelo en el conjunto de prueba: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:#800080'> Explicación: </span> Columna objetivo: Hemos utilizado la columna is_ultra como la columna que queremos predecir.\n",
    "Modelos: Usamos Logistic Regression, Random Forest y KNN y ajustamos sus hiperparámetros utilizando GridSearchCV.\n",
    "Evaluación: Comprobamos la precisión en el conjunto de validación y, finalmente, en el conjunto de prueba para determinar la calidad final del mejor modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:#008000'> ADICIONAL: Código para la prueba de cordura </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:#D2691E'> 1. Modelo Baseline (Regla trivial): </span>\n",
    "Este modelo simplemente predice siempre la clase mayoritaria (la que aparece con mayor frecuencia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo trivial (baseline) en el conjunto de validación: 0.7074688796680498\n"
     ]
    }
   ],
   "source": [
    "# Crear un modelo de regla trivial (siempre predice la clase mayoritaria)\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(train_data.drop('is_ultra', axis=1), train_data['is_ultra'])\n",
    "\n",
    "# Evaluar el modelo trivial en el conjunto de validación\n",
    "dummy_val_predictions = dummy_clf.predict(val_data.drop('is_ultra', axis=1))\n",
    "dummy_accuracy = accuracy_score(val_data['is_ultra'], dummy_val_predictions)\n",
    "\n",
    "print(f\"Precisión del modelo trivial (baseline) en el conjunto de validación: {dummy_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:#D2691E'>2. Aleatorización de etiquetas: </span>\n",
    "Este paso aleatoriza las etiquetas para ver si el modelo puede ajustarse a ruido puro. Debería obtener resultados similares a los de una predicción aleatoria si el modelo no está \"aprendiendo\" patrones reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo entrenado con etiquetas aleatorias: 0.7012448132780082\n"
     ]
    }
   ],
   "source": [
    "# Aleatorizar las etiquetas\n",
    "random_labels = np.random.permutation(train_data['is_ultra'])\n",
    "\n",
    "# Entrenar el modelo con etiquetas aleatorias\n",
    "model_with_random_labels = RandomForestClassifier()\n",
    "model_with_random_labels.fit(train_data.drop('is_ultra', axis=1), random_labels)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de validación\n",
    "random_val_predictions = model_with_random_labels.predict(val_data.drop('is_ultra', axis=1))\n",
    "random_accuracy = accuracy_score(val_data['is_ultra'], random_val_predictions)\n",
    "\n",
    "print(f\"Precisión del modelo entrenado con etiquetas aleatorias: {random_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:#D2691E'> 3. Comparación con el modelo real: </span>\n",
    "Finalmente, comparamos los resultados del modelo con etiquetas reales frente al modelo con etiquetas aleatorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del mejor modelo en el conjunto de validación (con etiquetas reales): 0.8236514522821576\n",
      "El modelo con etiquetas reales tiene un mejor rendimiento, lo que sugiere que el modelo no está ajustando ruido.\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo real (con etiquetas reales)\n",
    "real_val_predictions = best_model.predict(val_data.drop('is_ultra', axis=1))\n",
    "real_accuracy = accuracy_score(val_data['is_ultra'], real_val_predictions)\n",
    "\n",
    "print(f\"Precisión del mejor modelo en el conjunto de validación (con etiquetas reales): {real_accuracy}\")\n",
    "\n",
    "# Comparar con las etiquetas aleatorias\n",
    "if real_accuracy > random_accuracy:\n",
    "    print(\"El modelo con etiquetas reales tiene un mejor rendimiento, lo que sugiere que el modelo no está ajustando ruido.\")\n",
    "else:\n",
    "    print(\"El modelo no mejora con respecto a etiquetas aleatorias, podría estar ajustando ruido o datos superficiales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:#800080'> Explicación: </span>\n",
    "Modelo Baseline: Este modelo siempre predice la clase más frecuente en los datos de entrenamiento. Si tu modelo no es capaz de superar esta predicción trivial, algo está mal.\n",
    "\n",
    "Aleatorización de etiquetas: Entrenamos el modelo con etiquetas aleatorias para ver si puede ajustar patrones reales en lugar de ruido. Si el modelo real no tiene un mejor rendimiento que el modelo aleatorizado, significa que no está aprendiendo patrones significativos.\n",
    "\n",
    "Comparación: Comparamos la precisión de los modelos con etiquetas reales y aleatorias. El objetivo es que el modelo con etiquetas reales tenga una precisión significativamente mayor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:#0000FF'> Conclusión del análisis y pruebas realizadas: </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis realizado mostró que el modelo Random Forest fue el más efectivo para predecir si un usuario tiene el plan Ultra o Smart. Ajustamos los hiperparámetros utilizando GridSearchCV y logramos una precisión alta tanto en el conjunto de validación como en el conjunto de prueba.\n",
    "\n",
    "La prueba de cordura demostró que el modelo está aprendiendo patrones reales en los datos, ya que superó tanto al modelo trivial como al entrenado con etiquetas aleatorias. Esto confirma que el modelo no está ajustando ruido, sino que es capaz de generalizar bien.\n",
    "\n",
    "En resumen, el Random Forest es un modelo sólido y confiable para este problema."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 329,
    "start_time": "2024-10-03T14:30:57.170Z"
   },
   {
    "duration": 522,
    "start_time": "2024-10-03T14:31:06.624Z"
   },
   {
    "duration": 57,
    "start_time": "2024-10-03T14:32:05.462Z"
   },
   {
    "duration": 61,
    "start_time": "2024-10-03T14:33:29.699Z"
   },
   {
    "duration": 7,
    "start_time": "2024-10-03T14:33:44.501Z"
   },
   {
    "duration": 459,
    "start_time": "2024-10-03T14:35:23.749Z"
   },
   {
    "duration": 153,
    "start_time": "2024-10-03T14:35:42.584Z"
   },
   {
    "duration": 63,
    "start_time": "2024-10-03T14:35:52.569Z"
   },
   {
    "duration": 61,
    "start_time": "2024-10-03T14:37:42.469Z"
   },
   {
    "duration": 62,
    "start_time": "2024-10-03T14:37:58.612Z"
   },
   {
    "duration": 3,
    "start_time": "2024-10-03T14:38:29.206Z"
   },
   {
    "duration": 57,
    "start_time": "2024-10-03T14:38:36.242Z"
   },
   {
    "duration": 59,
    "start_time": "2024-10-03T14:40:02.352Z"
   },
   {
    "duration": 6,
    "start_time": "2024-10-03T14:41:42.335Z"
   },
   {
    "duration": 4,
    "start_time": "2024-10-03T14:41:51.216Z"
   },
   {
    "duration": 60,
    "start_time": "2024-10-03T14:42:25.419Z"
   },
   {
    "duration": 60,
    "start_time": "2024-10-03T14:44:16.933Z"
   },
   {
    "duration": 62,
    "start_time": "2024-10-03T14:46:30.154Z"
   },
   {
    "duration": 6,
    "start_time": "2024-10-03T14:50:46.681Z"
   },
   {
    "duration": 17,
    "start_time": "2024-10-03T14:51:43.230Z"
   },
   {
    "duration": 7,
    "start_time": "2024-10-03T14:56:13.460Z"
   },
   {
    "duration": 38,
    "start_time": "2024-10-03T15:17:21.943Z"
   },
   {
    "duration": 752,
    "start_time": "2024-10-03T15:22:00.392Z"
   },
   {
    "duration": 15407,
    "start_time": "2024-10-03T15:27:12.285Z"
   },
   {
    "duration": 20,
    "start_time": "2024-10-03T15:29:14.195Z"
   },
   {
    "duration": 3,
    "start_time": "2024-10-03T15:36:54.137Z"
   },
   {
    "duration": 5,
    "start_time": "2024-10-03T15:37:09.651Z"
   },
   {
    "duration": 4,
    "start_time": "2024-10-03T15:37:30.619Z"
   },
   {
    "duration": 392,
    "start_time": "2024-10-03T15:37:50.002Z"
   },
   {
    "duration": 21,
    "start_time": "2024-10-03T15:41:05.525Z"
   },
   {
    "duration": 786,
    "start_time": "2024-10-04T04:11:25.790Z"
   },
   {
    "duration": 604,
    "start_time": "2024-10-04T04:11:26.579Z"
   },
   {
    "duration": 0,
    "start_time": "2024-10-04T04:11:27.185Z"
   },
   {
    "duration": 0,
    "start_time": "2024-10-04T04:11:27.186Z"
   },
   {
    "duration": 0,
    "start_time": "2024-10-04T04:11:27.188Z"
   },
   {
    "duration": 0,
    "start_time": "2024-10-04T04:11:27.189Z"
   },
   {
    "duration": 0,
    "start_time": "2024-10-04T04:11:27.190Z"
   },
   {
    "duration": 0,
    "start_time": "2024-10-04T04:11:27.192Z"
   },
   {
    "duration": 3,
    "start_time": "2024-10-04T04:11:37.018Z"
   },
   {
    "duration": 17,
    "start_time": "2024-10-04T04:11:37.024Z"
   },
   {
    "duration": 6,
    "start_time": "2024-10-04T04:11:37.043Z"
   },
   {
    "duration": 15401,
    "start_time": "2024-10-04T04:11:37.051Z"
   },
   {
    "duration": 20,
    "start_time": "2024-10-04T04:11:52.455Z"
   },
   {
    "duration": 6,
    "start_time": "2024-10-04T04:11:52.477Z"
   },
   {
    "duration": 470,
    "start_time": "2024-10-04T04:11:52.485Z"
   },
   {
    "duration": 22,
    "start_time": "2024-10-04T04:11:52.958Z"
   },
   {
    "duration": 5,
    "start_time": "2024-10-04T04:13:38.950Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
